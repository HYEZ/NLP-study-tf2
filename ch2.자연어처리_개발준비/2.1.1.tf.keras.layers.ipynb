{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.1.tf.keras.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기 및 상수값 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20, 1)\n",
    "CONV_INPUT_SIZE = (1, 28, 28)\n",
    "IS_TRAINING = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer\n",
    "\n",
    "__Fully Connected Layer__ 이며,\n",
    "\n",
    "$ y = f(Wx + b) $ 의 식을 만족하는 기본적인 신경망 형태의 층을 만듬\n",
    "- 방법 1: 가중치인 W와 b를 각각 변수로 선언한 후 행렬곱을 통해 구하는 방법\n",
    "- 방법 2: 케라스의 Dense 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 10)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "# 방법 1\n",
    "W = tf.Variable(tf.random.uniform([5, 10], -1.0, 1.0)) # 5x10 가중치 벡터\n",
    "b = tf.Variable(tf.zeros([10])) # 1x10 편향벡터\n",
    "\n",
    "print(W.shape)\n",
    "print(b.shape)\n",
    "\n",
    "# y = tf.matmul(W, x) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 방법 2\n",
    "## 내부적으로 변수를 생성하고, 연산 진행.\n",
    "## 활성화함수, 초기화방법, 정규화방법 등을 인자로 쉽게 지정함\n",
    "\n",
    "# 1. 개체 생성 후 다시 호출하면서 입력값을 설정함\n",
    "dense = tf.keras.layers.Dense(...)\n",
    "output = dense(input)\n",
    "\n",
    "# 2. 개체 생성 시 입력값 설정 \n",
    "output = tf.keras.layers.Dense(...)(input)\n",
    "\n",
    "# tf.keras.layers.Dense의 인자들\n",
    "__init__(\n",
    "    units, # output size (Integer or Long)\n",
    "    activation=None, # 활성화함수\n",
    "    use_bias=True, # 편향ㅇ르 사용할지 여부\n",
    "    kernel_initializer='glort_uniform', # 가중치 초기화 함수\n",
    "    bias_initializer='zeros', # 편향 초기화 함수\n",
    "    kernel_regulaizer=None, # 가중치 정규화 방법\n",
    "    bias_regulaizer=None, # 편향 정규화 방법\n",
    "    activity_regularizer=None, # 출력 값 정규화 방법\n",
    "    kernel_constraint=None, # Optimizer에 의해 업데이트된 이후에 가중치에 적용하는 부가적인 제약함수\n",
    "    bias_constraint=None # Optimiezer에 의해 업데이트된 이후에 편향에 적용하는 부가적인 제약함수\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "output = tf.keras.layers.Dense(units=10, activation=tf.nn.sigmoid)(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer with 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "hidden = tf.keras.layers.Dense(units=10, activation=tf.nn.sigmoid)(inputs)\n",
    "output = tf.keras.layers.Dense(units=2, activation=tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 객체 생성 후 다시 호출하면서 입력값 설정\n",
    "dropout = tf.keras.layers.Dropout(...)\n",
    "output = dropout(input)\n",
    "\n",
    "# 2. 객체 생성 시 입력값 설정\n",
    "output = tf.keras.layers.Dropout(...)(input)\n",
    "\n",
    "# tf.keras.layers.Dropout의 인자들\n",
    "__init__(\n",
    "    rate, # 드롭아웃을 적용할 확률\n",
    "    noise_shape=None, # 정수형의 1d-tensor 를 받음. 특정 값만 드롭아웃을 적용할 수 있음\n",
    "    seed=None # 랜덤 시드 (같은 시드 값을 가지면 동일한 드롭아웃 결과를 만든다)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.5)(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer with 1 hidden layer and dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "hidden = tf.keras.layers.Dense(units=10, activation=tf.nn.sigmoid)(dropout)\n",
    "output = tf.keras.layers.Dense(units=2, activation=tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional layer\n",
    "\n",
    "합성곱 연산은 Conv1D, Conv2D, Conv3D 가 있음\n",
    "- Conv1D: 합성곱방향-한방향(가로), 출력값-(1D array)\n",
    "- Conv2D: 합성곱방향-두방향(세로), 출력값-(2D array)\n",
    "- Conv3D: 합성곱방향-세 방향(가로, 세로, 높이), 출력값-(3D array)\n",
    "\n",
    "NLP에서 합성곱의 경우 각 단어(혹은 문자) 벡터의 차원 전체에 대해 주로 Conv1D 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 객체 생성 후 다시 호출하면서 입력값 설정\n",
    "conv1d = tf.keras.layers.Conv1D(...)\n",
    "output = conv1d(input)\n",
    "\n",
    "# 2. 객체 생성 시 입력값 설정\n",
    "ouput = tf.kears.layers.Conv1D(...)(input)\n",
    "\n",
    "# tf.keras.layers.Conv1D의 인자들\n",
    "__init__(\n",
    "    filters, # 필터 개수 == 출력의 차원 수\n",
    "    kernel_size, # 필터의 크기(=window size)\n",
    "    strides=1, # 리스트 또는 튜플 형태. \n",
    "    padding='valid', # valid or same(입력값과 출력값 가로 크기 똑같게 함)\n",
    "    data_format='channel_last', # channel_last(batch, length, channels) or channel_first(batch, channels, length)\n",
    "    dilation_rate=1, \n",
    "    activation=None, \n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regulaizer=None,\n",
    "    activity_regulaizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=CONV_INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "        filters=10,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)(dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling\n",
    "합성곱신경망과 함께 쓰이는 기법. 보통 피처맵의 크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용함\n",
    "- MaxPool1D, MaxPool2D, MaxPool3D\n",
    "- 자연어처리에선 주로 MaxPool1D를 사용\n",
    "- 맥스 풀링 결과를 FC 레이어에 연결하려면 원래 행렬이였던걸 벡터로 바꿔주기 위해 tf.keras.layers.Flatten 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 객체 생성 후 apply 함수를 이용해 입력값 설정\n",
    "max_pool = tf.keras.layers.MaxPool1D(...)\n",
    "max_pool.apply(input)\n",
    "\n",
    "# 2. 객체 생성 시 입력값 설정\n",
    "max_pool = tf.keras.layers.MaxPool1D(...)(input)\n",
    "\n",
    "## tf.keras.layers.MaxPool1D의 인자들\n",
    "__init__(\n",
    "    pool_size=2, # 풀링을 적용할 필터의 크기 (정수값)\n",
    "    strides=None, # 적용할 스트라이드 값 \n",
    "    padding='valid', # 패딩 방법 (valid or same)\n",
    "    data_foramt=None # channel_last or channel_first\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input -> Dropout -> Convolutional layer -> MaxPooling -> Dense layer with 1 hidden layer -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=CONV_INPUT_SIZE[1:])\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "        filters=10,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        activation=tf.nn.relu)(dropout)\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size=3,\n",
    "                                     padding='same')(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "hidden = tf.keras.layers.Dense(units=50, activation=tf.nn.relu)(flatten)\n",
    "output = tf.keras.layers.Dense(units=10, activation=tf.nn.relu)(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
