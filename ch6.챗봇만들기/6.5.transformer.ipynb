{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 트랜스포머 네트워크 모듈 목룍\n",
    "1. 멀티헤드 어텐션 (Multi-head attention)\n",
    "2. 서브시퀀트 마스크 어텐션 (Subsequent masked attention)\n",
    "3. 포지션-와이드 피드 포워드 네트워크 (Position-wise feed fowrd network)\n",
    "4. 리지듀얼 커넥션(Residual connection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "\n",
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 데이터 경로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 인코더의 입력 (즉, question)\n",
    "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
    "\n",
    "# 디코더의 입력 (즉, answer)\n",
    "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'rb'))\n",
    "\n",
    "# 디코더의 타겟 (즉, answer)\n",
    "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS , 'rb'))\n",
    "\n",
    "# word2idx, idx2word, vocab_size, 기호 인덱스(pad, std, end, unk)\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7237 19975     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0]\n",
      "[    1  1092  6458  5726 17918     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0]\n",
      "[ 1092  6458  5726 17918     2     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0]\n",
      "11823 (11823, 25)\n",
      "11823 (11823, 25)\n",
      "11823 (11823, 25)\n"
     ]
    }
   ],
   "source": [
    "print(index_inputs[0]) # 인코더의 입력\n",
    "print(index_outputs[0]) # 디코더의 입력\n",
    "print(index_targets[0]) # 디코더의 타겟\n",
    "print(len(index_inputs), index_inputs.shape )\n",
    "print(len(index_outputs), index_outputs.shape)\n",
    "print(len(index_targets), index_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 하이퍼파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "model_name = \"transformer\"\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCHS = 3 #30\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "kargs = {\n",
    "    'model_name': model_name,\n",
    "    'num_layers': 2,\n",
    "    'd_model': 512, # key, query, value의 차원\n",
    "    'num_heads': 8, # 어텐션 헤드 수\n",
    "    'dff': 2048, # position-wise FFN 차원 수\n",
    "    'input_vocab_size': vocab_size,\n",
    "    'target_vocab_size': vocab_size,\n",
    "    'maximum_position_encoding': MAX_SEQUENCE, # 25\n",
    "    'end_token_idx': char2idx[end_index],\n",
    "    'rate':0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 선언 및 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) 패딩 및 포워드 마스킹 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    # 남은 차원을 0으로 채움\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 순방향으로 어텐션 맵을 마스킹한다.\n",
    "# 순방햐 어텐션 시 (즉 순서가있는 단어에 대한 관계) 사용하는 순방향 마스크\n",
    "def create_look_ahead_mask(size):\n",
    "    # 마스킹할 영역은 1, 아닌 영역은 0으로 만든다.\n",
    "    # 즉, 아래쪽 삼각형이 0이 되는 하삼각행렬을 만듬\n",
    "    \n",
    "    # tf.ones 로 모든 값이 1인 행렬 만듬\n",
    "    # 그 다음 아래쪽 삼각형을 0으로 채움\n",
    "    # (input, 0, -1) ==> Upper triangular part.\n",
    "    # (input, -1, 0) ==> Lower triangular part. 즉, 우리는 아래쪽을 0으로 채울거라서 이거 사용\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0) # 입력행렬, -1, 0\n",
    "    return mask # (seq_len, seq_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(index_inputs, index_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) 포지셔널 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 각 순서에 따른 sin, cos 함수 각도값 얻기\n",
    "# pos: 포지션에 대한 인덱스 위치 리스트\n",
    "# i: 차원에 대한 리스트\n",
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2*i//2) / np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 포지션 임베딩 만들기\n",
    "def positional_encoding(position, d_model): # 25, 512\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "    print(np.arange(position)[:, np.newaxis].shape)\n",
    "    print(np.arange(d_model)[np.newaxis, :].shape)\n",
    "    print(angle_rads.shape)\n",
    "    \n",
    "    # 짝수 => sin\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    # 홀수 => cos\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    print(pos_encoding.shape)\n",
    "#     print(type(pos_encoding))\n",
    "\n",
    "    # (배치차원, 시퀀스차원, 피처차원)\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32) # 넘파이를 텐서로 바꿈\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1)\n",
      "(1, 512)\n",
      "(50, 512)\n",
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "# print(type(pos_encoding))\n",
    "# print(pos_encoding)\n",
    "\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "# 이 차트 보면.. \n",
    "# depth 깊어질수록 임베딩 뒤차원의 값은 거의 0..\n",
    "# position은 뒤로 갈수록(커질수록) 값이 depth 앞차원쪽에 몰려있음. (뒤차원 0값이 늘어남)\n",
    "# 그리고 depth 커질수록 임베딩값 커졌다 작아졌다 하는걸 보니깐 짝수, 홀수에 대한 값 같음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n",
      "tf.Tensor(\n",
      "[ 0.74511313 -0.01696658  0.77540296  0.98017985 -0.4584321   0.41773638\n",
      " -0.97571594 -0.75848997 -0.08096503 -0.85950977  0.9098894   0.16715014\n",
      "  0.72961646  0.97059757 -0.31582433  0.64047223 -0.98867553 -0.37475243\n",
      " -0.614248   -0.98942447  0.35331333 -0.65338385  0.97517693  0.25396407\n",
      "  0.74632543  0.9288744  -0.07532834  0.86676145 -0.81969917  0.17801827\n",
      " -0.97031087 -0.6131116  -0.4816219  -0.9948548   0.28823665 -0.7780549\n",
      "  0.8719563  -0.13799322  0.9741002   0.554764    0.58845377  0.9605351\n",
      " -0.05916608  0.9233052  -0.66180307  0.50070816 -0.9786478  -0.10452747\n",
      " -0.91676193 -0.65306264 -0.53441375 -0.96277225  0.011204   -0.95794374\n",
      "  0.53617764 -0.6705424   0.8916597  -0.20785695  0.99892426  0.29322684\n",
      "  0.85547256  0.70800424  0.5193704   0.95161617  0.08264565  0.9898257\n",
      " -0.35625705  0.835475   -0.714187    0.5358223  -0.9361187   0.15628901\n",
      " -0.9991225  -0.23496167 -0.9093901  -0.5788873  -0.6949922  -0.83278114\n",
      " -0.39695632 -0.9730023  -0.06067956 -0.9941314   0.2710514  -0.90576386\n",
      "  0.56285983 -0.72812814  0.7893634  -0.48749506  0.9358551  -0.2120543\n",
      "  0.9975618   0.07136068  0.9779955   0.33955568  0.88686115  0.5742999\n",
      "  0.7378857   0.76282924  0.5468241   0.89771795  0.32979187  0.9763159\n",
      "  0.10199121  0.99993193 -0.12316566  0.97290987 -0.3345741   0.90170974\n",
      " -0.5236545   0.79406613 -0.6843387   0.65827096 -0.8128914   0.502597\n",
      " -0.90762764  0.3348657  -0.9685745   0.16214868 -0.9971171  -0.00941578\n",
      " -0.99565434 -0.17471014 -0.96728545 -0.32965085 -0.9155361  -0.47114688\n",
      " -0.8441293  -0.5970206  -0.7568025  -0.705906   -0.65716684 -0.79713476\n",
      " -0.54860556 -0.8706205  -0.4342053  -0.926746   -0.31671542 -0.9662586\n",
      " -0.1985297  -0.9901761  -0.08168498 -0.99970454  0.032127   -0.9961683\n",
      "  0.14153892 -0.9809521   0.24548115 -0.95545375  0.34315172 -0.9210476\n",
      "  0.4339848  -0.8790567   0.5176193  -0.8307319   0.59386843 -0.7772387\n",
      "  0.66269153 -0.7196481   0.7241675  -0.65893257  0.77847177 -0.59596515\n",
      "  0.8258547  -0.531521    0.8666241  -0.46628124  0.9011289  -0.40083763\n",
      "  0.92974603 -0.33569875  0.95286924 -0.27129626  0.97089964 -0.20799169\n",
      "  0.98423845 -0.14608313  0.9932807  -0.08581182  0.998411   -0.02736848\n",
      "  0.99999934  0.02910067  0.9983992   0.08348837  0.9939451   0.13572112\n",
      "  0.98695207  0.1857545   0.9777144   0.23356885  0.9665061   0.2791655\n",
      "  0.95358074  0.32256326  0.9391719   0.36379537  0.9234939   0.40290692\n",
      "  0.90674275  0.4399524   0.8890967   0.47499365  0.87071747  0.5080982\n",
      "  0.85175127  0.53933746  0.8323297   0.56878597  0.8125709   0.5965196\n",
      "  0.7925804   0.6226152   0.77245235  0.6471495   0.75227     0.67019856\n",
      "  0.73210704  0.6918373   0.7120283   0.71213895  0.69209045  0.7311749\n",
      "  0.67234284  0.74901426  0.652828    0.76572376  0.63358265  0.78136766\n",
      "  0.6146379   0.7960076   0.59602004  0.8097024   0.57775104  0.82250834\n",
      "  0.5598487   0.83447903  0.5423276   0.8456653   0.52519894  0.85611546\n",
      "  0.5084713   0.8658753   0.4921508   0.8749881   0.47624126  0.8834946\n",
      "  0.46074465  0.8914336   0.44566125  0.8988413   0.43098992  0.905752\n",
      "  0.4167282   0.91219795  0.4028725   0.9182093   0.38941833  0.9238146\n",
      "  0.37636036  0.9290405   0.36369252  0.93391204  0.35140824  0.9384527\n",
      "  0.33950043  0.94268453  0.3279616   0.94662803  0.31678393  0.9503025\n",
      "  0.30595943  0.95372605  0.29547977  0.95691544  0.28533664  0.95988655\n",
      "  0.27552158  0.9626541   0.26602602  0.9652318   0.2568415   0.9676326\n",
      "  0.24795951  0.9698684   0.23937157  0.9719506   0.23106933  0.97388947\n",
      "  0.22304448  0.9756949   0.21528888  0.9773759   0.20779444  0.97894114\n",
      "  0.20055327  0.9803984   0.19355758  0.98175514  0.18679976  0.9830183\n",
      "  0.18027237  0.98419416  0.1739681   0.9852888   0.16787985  0.98630786\n",
      "  0.16200067  0.98725647  0.1563238   0.98813945  0.15084264  0.9889614\n",
      "  0.14555077  0.9897265   0.14044195  0.9904386   0.13551015  0.99110144\n",
      "  0.13074942  0.9917184   0.12615407  0.99229264  0.12171854  0.9928271\n",
      "  0.11743746  0.9933245   0.11330559  0.9937875   0.10931788  0.9942184\n",
      "  0.10546941  0.9946195   0.10175545  0.99499273  0.09817138  0.9953401\n",
      "  0.09471277  0.9956634   0.09137529  0.9959643   0.08815479  0.9962443\n",
      "  0.08504721  0.9965049   0.08204866  0.99674743  0.07915538  0.9969731\n",
      "  0.07636371  0.99718314  0.07367012  0.99737865  0.07107121  0.99756056\n",
      "  0.06856368  0.9977299   0.06614435  0.99788743  0.06381016  0.99803406\n",
      "  0.06155812  0.9981705   0.05938536  0.99829745  0.05728912  0.99841565\n",
      "  0.05526672  0.9985256   0.05331556  0.99862796  0.05143318  0.9987232\n",
      "  0.04961713  0.99881184  0.0478651   0.99889433  0.04617485  0.99897105\n",
      "  0.04454421  0.9990425   0.04297108  0.99910897  0.04145344  0.9991708\n",
      "  0.03998933  0.99922836  0.03857689  0.99928194  0.03721429  0.9993318\n",
      "  0.03589977  0.99937814  0.03463165  0.99942136  0.03340828  0.99946153\n",
      "  0.0322281   0.9994989   0.03108959  0.99953365  0.02999127  0.9995661\n",
      "  0.02893173  0.9995962   0.0279096   0.9996242   0.02692356  0.9996503\n",
      "  0.02597234  0.99967456  0.02505472  0.99969715  0.0241695   0.9997182\n",
      "  0.02331555  0.99973774  0.02249176  0.999756    0.02169706  0.9997729\n",
      "  0.02093044  0.9997887   0.02019089  0.99980336  0.01947747  0.999817\n",
      "  0.01878925  0.9998297   0.01812534  0.9998415   0.01748489  0.99985254\n",
      "  0.01686706  0.9998628   0.01627106  0.99987227  0.01569611  0.99988115\n",
      "  0.01514148  0.99988943  0.01460645  0.99989706  0.01409031  0.9999042\n",
      "  0.01359241  0.9999109   0.01311211  0.9999171   0.01264877  0.9999228\n",
      "  0.01220181  0.9999282   0.01177064  0.9999332   0.0113547   0.99993783\n",
      "  0.01095346  0.9999421   0.0105664   0.9999461   0.01019301  0.9999499\n",
      "  0.00983282  0.9999534   0.00948535  0.9999566   0.00915017  0.9999596\n",
      "  0.00882682  0.99996245  0.0085149   0.999965    0.00821401  0.99996746\n",
      "  0.00792374  0.9999697   0.00764374  0.9999718   0.00737362  0.9999738\n",
      "  0.00711306  0.9999756   0.0068617   0.9999773   0.00661922  0.99997884\n",
      "  0.00638531  0.99998033  0.00615967  0.9999817   0.005942    0.99998295\n",
      "  0.00573202  0.99998415  0.00552946  0.9999853   0.00533406  0.9999863\n",
      "  0.00514557  0.99998724  0.00496373  0.99998814  0.00478832  0.9999889\n",
      "  0.00461911  0.9999897   0.00445588  0.9999904   0.00429842  0.99999106\n",
      "  0.00414652  0.9999917 ], shape=(512,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(pos_encoding.shape)\n",
    "print(pos_encoding[0, 40]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# qurey, key, value가 각각 단어벡터가 모인 행렬로 들어옴\n",
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    # query와 key 내적\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)   # (..., seq_len_q, seq_len_k) \n",
    "    \n",
    "    # 스케일링\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32) # k의 차원\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    # 마스크\n",
    "    if mask is not None:\n",
    "        # 마스킹된 부분(1) * -10^9 하면 10^9 값을 빼줄 수 있게 됨 \n",
    "        # => 마스킹 된 부분의 어텐션 점수가 매우 작아짐 (매우 작은 음수값 가짐)\n",
    "        # => softmax 취하면 거의 0에 수렴함\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "    # softmax 취해서 어텐션 점수 구하기\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=1)   # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # 어텐션 점수와 value 가중합 구하기\n",
    "    output = tf.matmul(attention_weights, v) # (..., seq_len_q, depth_v)\n",
    "    \n",
    "    # 문맥 벡터, 어텐션 점수 리턴\n",
    "    return output, attention_weights \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) 멀티헤드 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # 어텐션 헤드 수\n",
    "        self.num_heads = kargs['num_heads'] # 여기서는 8개\n",
    "        \n",
    "        # key, query, value에 대한 차원을 정의하기 위한 파라미터\n",
    "        # => 어텐션 헤드 수만큼 나눠지는 것!\n",
    "        self.d_model = kargs['d_model'] # 512 \n",
    "        \n",
    "        # 따라서 d_model // num_heads 했을때 나머지가 발생하면 안된다.\n",
    "        # assert는 값이 false이면 에러 발생시킴. 즉 나머지 발생 시 에러남\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "        \n",
    "        # 나머지가 0이면, 그 나눈 값을 depth에 저장함\n",
    "        # depth는 각 헤드에 입력될 벡터의 차원 수이다. (512//8=64)\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        \n",
    "        # key, query, value에 대한 차원 수를 맞추기 위함\n",
    "        # 스케일 내적 어텐션 연산 이전에 있는 Linear\n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "        # 셀프 어텐션 마지막 출력 레이어\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "    \n",
    "    # 각 key, query, value에 대한 벡터를 어텐션 헤드 수만큼 분리하는 함수\n",
    "    # (배치차원, 시퀀스차원, 피처차원) => (배치차원, 헤드차원, 시퀀스차원, 피처차원)\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \n",
    "        # num_heads, depth : 하이퍼 파리미터 (이미 정해짐)\n",
    "        # 시퀀스크기 : 학습하는 도중 배치 데이터의 시퀀스 길이가 매번 바뀔 수도 있음 \n",
    "        # => 따라서 시퀀스 길이는 -1 로 정하고, batch_size값을 알아야하므로 인자로 정의하게 됨\n",
    "        #       *** 참고) tf.reshape은 값을 하나만 모를 경우 가능 \n",
    "        # (배치차원, 시퀀스차원, 헤드차원, 피처차원)으로 리턴\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        \n",
    "        # (배치차원, 헤드차원, 시퀀스차원, 피처차원) 으로 바꿔줌\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0] # batch_size\n",
    "        \n",
    "        q = self.wq(q) # (batch_size, seq_len, d_model=512)\n",
    "        k = self.wq(k) # (batch_size, seq_len, d_model)\n",
    "        v = self.wq(v) # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth=d_model/num_heads=64)\n",
    "        k = self.split_heads(k, batch_size) # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size) # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # 내적 어텐션 적용 => 각 시퀀스마다 단어에 대한 context vector 구해짐 * 어텐션헤드 수\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        # (batch_size, seq_len_q, num_heads, depth)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # 모든 어텐션 헤드 concat\n",
    "        # (batch_size, seq_len_q, d_model)\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                     (batch_size, -1, self.d_model))\n",
    "        \n",
    "        # 마지막 dense 레이어로 출력 (멀티 헤드 어텐션 벡터 출력)\n",
    "        # (batch_size, seq_len_q, d_model)\n",
    "        output = self.dense(concat_attention)\n",
    "        \n",
    "        return output, attention_weights\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) 포인트 와이즈 피드포워드 네트워크 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "        # (batch_size, seq_len, dff=2048)\n",
    "        tf.keras.layers.Dense(kargs['dff'], activation='relu'),\n",
    "        \n",
    "        # (batch_size, seq_len, d_model)\n",
    "        tf.keras.layers.Dense(kargs['d_model'])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 여러개의 인코더 레이어를 쌓을 수 있도록 준비\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # 오버피팅 막고 모델 일반화를 위해 드롭아웃 적용\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    def call(self, x, mask):\n",
    "        \n",
    "        # 1-1. 멀티 헤드 어텐션에 넣기\n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        # 셀프 어텐션을 하기 때문에 v, k, q가 모두 동일함\n",
    "        attn_output, _ = self.mha(x, x, x, mask) # v, k, q, mask\n",
    "        # 1-2. 드롭아웃\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        # 1-3. 리지듀얼 커넥션 + 층정규화\n",
    "        out1 = self.layernorm1(x + attn_output) # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # 2-1. FFN\n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        # 2-2. 드롭아웃\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        # 2-3. 리지듀얼 커넥션 + 층정규화\n",
    "        out2 = self.layernorm2(out1 + ffn_output) \n",
    "        \n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        return out2\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 디코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(**kargs)\n",
    "        self.mha2 = MultiHeadAttention(**kargs)\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # 디코더 입력, 인코더 출력(각 단어의 context vector), 순방향 마스크, 패딩 마스크\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # 1) 디코더의 입력사이의 관계를 계산하는 셀프어텐션\n",
    "        # (batch_size, target_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, # value\n",
    "                                               x, # key \n",
    "                                               x, # query\n",
    "                                               look_ahead_mask) # 순방향 마스크\n",
    "        attn1 = self.dropout1(attn1) # 드롭아웃\n",
    "        out1 = self.layernorm1(attn1 + x) # residual + 층 정규화\n",
    "                                        # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        # 2) 인코더의 결과값과 디코더의 셀프어텐션 결과값의 관계를 계산하는 어텐션\n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, # vlaue\n",
    "                                              enc_output, # key\n",
    "                                              out1, # query\n",
    "                                              padding_mask) # 패딩마스크 \n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm2(attn2 + out1) # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        # 3) point-wise FFN\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(ffn_output + out2) # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 전체적인 인코더 클래스\n",
    "# 인코더 레이어, 워드 임베딩, 포지션 인코더 등으로 구성됨\n",
    "\n",
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 멀티헤드어텐션의 context vector 차원, 512\n",
    "        # 각 헤드 차원은 512/8=64 임 (얘네 8개 concat 시켜서 최종 mha 출력 차원은 512)\n",
    "        self.d_model = kargs['d_model'] \n",
    "        \n",
    "        self.num_layers = kargs['num_layers'] # 인코더 레이어의 개수\n",
    "        \n",
    "        # 임베딩 레이어\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], # vocab size\n",
    "                                                  self.d_model) # 출력차원\n",
    "        \n",
    "        # 포지션 인코딩\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], # 25\n",
    "                                               self.d_model)\n",
    "        \n",
    "        # 인코더 레이어 x2\n",
    "        self.enc_layers = [EncoderLayer(**kargs)\n",
    "                          for _ in range(self.num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    def call(self, x, mask):\n",
    "        seq_len = tf.shape(x)[1] # 시퀀스 길이 (max는 25지만 각 시퀀스 길이는 다르다!)\n",
    "        \n",
    "        \n",
    "        # 임베딩\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        # 루트 d_model 만큼 스케일링\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        # 포지션 인코딩\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        # 드롭아웃\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, mask)\n",
    "        \n",
    "        # (batch_size, input_seq_len, d_model)\n",
    "        return x\n",
    "         \n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.d_model = kargs['d_model'] # 512\n",
    "        self.num_layers = kargs['num_layers'] # 512\n",
    "        \n",
    "        # 임베딩\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'],\n",
    "                                                  self.d_model) \n",
    "        # 포지션 인코딩\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], #25  \n",
    "                                                self.d_model)\n",
    "        \n",
    "        # 디코더 레이어\n",
    "        self.dec_layers = [DecoderLayer(**kargs) \n",
    "                           for _ in range(self.num_layers)]\n",
    "        \n",
    "        # 드롭아웃\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1] # 시퀀스 길이\n",
    "        attention_weights = {}\n",
    "        \n",
    "        # 임베딩\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        \n",
    "        # 스케일링\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        \n",
    "        # 포지션 인코딩 시퀀스 길이만큼 잘라주기\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        # 드롭아웃 적용\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, \n",
    "                                                   enc_output, \n",
    "                                                   look_ahead_mask,\n",
    "                                                   padding_mask)\n",
    "        attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "        attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    \n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트렌스포머 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 인코더와 디코더를 이어서 시퀀스 투 시퀀스 모델 형태로 구현한다.\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Transformer, self).__init__(name=kargs['model_name'])\n",
    "        self.end_token_idx = kargs['end_token_idx']\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)\n",
    "        self.decoder = Decoder(**kargs)\n",
    "        \n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
    "    \n",
    "    # 학습을 위한 함수 (디코더 입력이 주어짐)\n",
    "    def call(self, x):\n",
    "        inp, tar = x # question, answer\n",
    "        \n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask) # (batch_size, inp_seq_len, d_model)\n",
    "        \n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, _ = self.decoder(tar,\n",
    "                                    enc_output,\n",
    "                                    look_ahead_mask,\n",
    "                                    dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output)\n",
    "        # (batch_size, tar_seq_len, target_vocab_size)\n",
    "        \n",
    "        return final_output\n",
    "    \n",
    "    # 추론을 위한 함수 (디코더 입력이 주어지지 않음. 매번 생성해야함)\n",
    "    def inference(self, x):\n",
    "        inp = x\n",
    "        tar = tf.expand_dims([STD_INDEX], 0)\n",
    "        \n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)        \n",
    "        \n",
    "        # 인코더에 넣음\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE):\n",
    "            dec_output, _ = self.decoder(tar,\n",
    "                                        enc_output,\n",
    "                                        look_ahead_mask,\n",
    "                                        dec_padding_mask) # (batch_size, tar_seq_len, d_model)\n",
    "            final_output = self.final_layer(dec_output) # (batch_size, tar_seq_len, target_vocab_size)\n",
    "            \n",
    "            # 가장 큰 단어 가져옴\n",
    "            outputs = tf.argmax(final_output, -1).numpy() \n",
    "            pred_token = outputs[0][-1]\n",
    "            \n",
    "            if pred_token == self.end_token_idx:\n",
    "                break\n",
    "            \n",
    "            predict_tokens.append(pred_token)\n",
    "            \n",
    "            tar = tf.expand_dims([STD_INDEX] + predict_tokens, 0)\n",
    "            \n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "            \n",
    "        return predict_tokens\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 로스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 1)\n",
      "(1, 512)\n",
      "(25, 512)\n",
      "(1, 25, 512)\n",
      "(25, 1)\n",
      "(1, 512)\n",
      "(25, 512)\n",
      "(1, 25, 512)\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=loss,\n",
    "              metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callback 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/transformer -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    /Users/ohyeji/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-185-65b92d2ffab2>:20 call  *\n        dec_output, _ = self.decoder(tar,\n    <ipython-input-197-0e1bd2f9abc8>:39 call  *\n        x, block1, block2 = self.dec_layers[i](x,\n    <ipython-input-195-1e6198ca3227>:44 call  *\n        ffn_output = self.dropout(ffn_output)\n\n    AttributeError: 'DecoderLayer' object has no attribute 'dropout'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-fc9f8e6eeaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVALID_SPLIT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     callbacks=[earlystop_callback, cp_callback])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /Users/ohyeji/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-185-65b92d2ffab2>:20 call  *\n        dec_output, _ = self.decoder(tar,\n    <ipython-input-197-0e1bd2f9abc8>:39 call  *\n        x, block1, block2 = self.dec_layers[i](x,\n    <ipython-input-195-1e6198ca3227>:44 call  *\n        ffn_output = self.dropout(ffn_output)\n\n    AttributeError: 'DecoderLayer' object has no attribute 'dropout'\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([index_inputs, index_outputs],\n",
    "                    index_targets,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=VALID_SPLIT,\n",
    "                    callbacks=[earlystop_callback, cp_callback])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
