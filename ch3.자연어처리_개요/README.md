# 자연어처리 개요
자연어처리는 어떤 문제(task)를 해결하느냐에 따라 분류한다.

## 자연어처리의 핵심 문제
이 책에서는 4개의 문제를 각각 살펴봄
1. 텍스트 분류
2. 텍스트 유사도
3. 텍스틑 생성
4. 기계 이해

### 1. 텍스트 분류
특정 텍스트를 사람이 정한 몇가지 범주(class)에 속하는지 분류하는 문제
- 스팸 분류
    - 메일이 스펨인지 아닌지 분류하는 binary classification
- 감정 분류
    - 주어진 글에 대해 이 글이 긍정인지 부정인지 (or 중립) 판단하는 문제(binary classification or multi class classification)
    - ex) 영화 리뷰에 대해 각 리뷰가 긍정이닞 부정인지 판단하는 문제 (4장에서 다룰 것)
- 뉴스 기사 분류
    - 스포츠, 경제, 사회, 연예 등 각 주제에 맞게 뉴스를 분류하는 문제(multi class classificaton)
- 품사 분류(=품사 태깅, POS)
    - 각 단어를 기준으로 어떤 품사를 가지는지 분류하는 문제

각 문제는 지도학습 또는 비지도학습을 통해 해결할 수 있음
- 지도학습을 통한 텍스트 분류
    - 나이브 베이즈 분류
    - 서포트 벡터 머신
    - 신경망
    - 선형 분류
    - 로지스틱 분류
    - 랜덤 포레스트
- 비지도학습을 통한 텍스트 분류
    - K-means Clustering
    - Hierarchicla Custering

### 2. 텍스트 유사도
텍스트가 유사한지 측정
- 단순히 같은 단어의 개수를 사용해서 유사도를 판단하는 방법
- 형태소로 나누어 형태소를 비교하는 방법
- 자소 단위로 나누어 단어를 비교하는 방법
- 딥러닝을 기반으로 유사도를 측쩡하는 방식 (이 책에서 주로 다룸)
4개의 유사도 측정 방법
- 자카드 유사도, 유클리디언 유사도, 맨하탄 유사도, 코사인 유사도

### 3. 텍스틑 생성
### 4. 기계 이해

## 단어 표현(=단어 벡터, 단어 임베딩)
자연어를 어떻게 표현할지 정하는 것을 먼저 살펴보자.
> 어떻게 자연어를 컴퓨터에게 인식시킬 수 있을까?
이 챕터에선 컴퓨터가 텍스트를 인식하는 기본적인 방법에 대해서 알아봄
- 텍스트를 유니코드 또는 아스키코드로 이진화하는 것의 문제점
    - 언어적인 특성이 전혀 없이 컴퓨터를 인식하기 위해 만들어진 값이므로 자연어처리를 위해 만드는 모델에 적용시키기엔 부적합함
    - 이를 해결하기 위한 방식은 `단어 표현(word representation)` 이다. 
        - 언어적인 특성을 반영해 단어를 수치화하는것!
        - 단어를 주로 벡터로 만듬
            - 따라서 단어 표현은 `단어 임베딩` 또는 `단어 벡터`로 표현하기도 한다.

### 원핫 인코딩
- 큰 데이터셋에서 단어 벡터의 크기가 너무 커져서 공간을 많이 차지, 비효율적 (sparse)
- 단순히 단어가 뭔지만 알려주고, 벡터값 자체에는 단어의 의미나 특성이 반영되지 않음
따라서 벡터의 크기가 작으면서도 벡터가 단어의 의미를 표현하는 방법들이 등장

### 분포 가설 기반 방법
같은 문맥의 단어, 즉 비슷한 위치에 나오는 단어는 비슷한 의미를 가진다. 
즉, 비슷한 위치에 존재하는 단어는 단어 간의 유사도가 높다고 판단 (크게 2가지 방법)

#### 1. 카운트 기반 방법
- 특정 문맥 안에서 단어들이 동시에 등장하는 횟수를 직접 세는 방법
- 동시 발생(Co-occurence)
    - 동시에 등장하는 횟수
- 동시 발생 행렬 (Co-occurence Matrix)
    - 단어들이 동시에 발생하는 횟수를 행렬로 나타낸 것
    - 동시발생 해열ㄹ을 ㅁ나들고 그 행렬을 수치화해서 벡터로 만드는 방법
        1. 특이값 분해 (SVD)
        2. 잠재의미분석 (LSA)
        3. Hyperspace Analogue to Language(HAL)
        4. Hellinger PCA
- 장점 
    - 빠르다(적은 시간으로 단어벡터를 만들 수 있음)
    - 데이터가 많을 경우에는 단어가 잘 표현되고 효율적이여서 아직도 많이 사용됨


#### 2. 예측 방법
- 신경망 등을 통해 문맥 안에 어떤 단어가 나올지를 예측하면서 단어를 벡터로 만드는 방법
- 예측기반 방법들
    1. Word2Vec(가장 많이 사용)
        1. CBOW 
            - 어떤 단어를 문맥 안의 주변 단어들을 통해 예측하는 방법
        2. SKip-Gram (보통 CBOW보다 성능이 좋음. 항상 좋은건 아님)
            - 어떤 단어를 가지고 특정 문맥 안의 주변 단어들을 예측하는 방법
        - 가중치 행렬의 각 행을 단어 벡터로 사용
        - 장점
            - 카운트 기반 방법보다 단어간의 유사도를 더 잘 측정함
            - 단어들의 복잡한 특징까지도 잘 잡아낸다는 점
            - 서로에게 유의미한 관계를 측정할 수 있다는 점
    2. NNLM (Nerual Network Language Model)
    3. RNNLM (Recurrent Neural Network Language Model)

#### Glove
- 카운트기반 + 예측기반


## 데이터 이해
데이터를 이해하는 것은 매우 중요함.
단순히 데이터를 사용하는것 보다 데이터가 어떤 구조이고, 어떤특성이 있는지 파악한 후에 모델을 만들자.