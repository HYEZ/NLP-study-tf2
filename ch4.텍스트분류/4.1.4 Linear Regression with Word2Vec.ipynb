{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1.3 Linear Regression Example with Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Feature Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_IN_PATH = '../dataset/'\n",
    "TRAIN_CLEAN_DATA = 'train_clean.csv'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(DATA_IN_PATH + TRAIN_CLEAN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = list(train_data['review'])\n",
    "sentiments = list(train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for review in reviews:\n",
    "    sentences.append(word_tokenize(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stuff',\n",
       " 'going',\n",
       " 'moment',\n",
       " 'mj',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'odd',\n",
       " 'documentary',\n",
       " 'watched',\n",
       " 'wiz',\n",
       " 'watched',\n",
       " 'moonwalker',\n",
       " 'maybe',\n",
       " 'want',\n",
       " 'get',\n",
       " 'certain',\n",
       " 'insight',\n",
       " 'guy',\n",
       " 'thought',\n",
       " 'really',\n",
       " 'cool',\n",
       " 'eighties',\n",
       " 'maybe',\n",
       " 'make',\n",
       " 'mind',\n",
       " 'whether',\n",
       " 'guilty',\n",
       " 'innocent',\n",
       " 'moonwalker',\n",
       " 'part',\n",
       " 'biography',\n",
       " 'part',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'remember',\n",
       " 'going',\n",
       " 'see',\n",
       " 'cinema',\n",
       " 'originally',\n",
       " 'released',\n",
       " 'subtle',\n",
       " 'messages',\n",
       " 'mj',\n",
       " 'feeling',\n",
       " 'towards',\n",
       " 'press',\n",
       " 'also',\n",
       " 'obvious',\n",
       " 'message',\n",
       " 'drugs',\n",
       " 'bad',\n",
       " 'kay',\n",
       " 'visually',\n",
       " 'impressive',\n",
       " 'course',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'unless',\n",
       " 'remotely',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'anyway',\n",
       " 'going',\n",
       " 'hate',\n",
       " 'find',\n",
       " 'boring',\n",
       " 'may',\n",
       " 'call',\n",
       " 'mj',\n",
       " 'egotist',\n",
       " 'consenting',\n",
       " 'making',\n",
       " 'movie',\n",
       " 'mj',\n",
       " 'fans',\n",
       " 'would',\n",
       " 'say',\n",
       " 'made',\n",
       " 'fans',\n",
       " 'true',\n",
       " 'really',\n",
       " 'nice',\n",
       " 'actual',\n",
       " 'feature',\n",
       " 'film',\n",
       " 'bit',\n",
       " 'finally',\n",
       " 'starts',\n",
       " 'minutes',\n",
       " 'excluding',\n",
       " 'smooth',\n",
       " 'criminal',\n",
       " 'sequence',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'convincing',\n",
       " 'psychopathic',\n",
       " 'powerful',\n",
       " 'drug',\n",
       " 'lord',\n",
       " 'wants',\n",
       " 'mj',\n",
       " 'dead',\n",
       " 'bad',\n",
       " 'beyond',\n",
       " 'mj',\n",
       " 'overheard',\n",
       " 'plans',\n",
       " 'nah',\n",
       " 'joe',\n",
       " 'pesci',\n",
       " 'character',\n",
       " 'ranted',\n",
       " 'wanted',\n",
       " 'people',\n",
       " 'know',\n",
       " 'supplying',\n",
       " 'drugs',\n",
       " 'etc',\n",
       " 'dunno',\n",
       " 'maybe',\n",
       " 'hates',\n",
       " 'mj',\n",
       " 'music',\n",
       " 'lots',\n",
       " 'cool',\n",
       " 'things',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'turning',\n",
       " 'car',\n",
       " 'robot',\n",
       " 'whole',\n",
       " 'speed',\n",
       " 'demon',\n",
       " 'sequence',\n",
       " 'also',\n",
       " 'director',\n",
       " 'must',\n",
       " 'patience',\n",
       " 'saint',\n",
       " 'came',\n",
       " 'filming',\n",
       " 'kiddy',\n",
       " 'bad',\n",
       " 'sequence',\n",
       " 'usually',\n",
       " 'directors',\n",
       " 'hate',\n",
       " 'working',\n",
       " 'one',\n",
       " 'kid',\n",
       " 'let',\n",
       " 'alone',\n",
       " 'whole',\n",
       " 'bunch',\n",
       " 'performing',\n",
       " 'complex',\n",
       " 'dance',\n",
       " 'scene',\n",
       " 'bottom',\n",
       " 'line',\n",
       " 'movie',\n",
       " 'people',\n",
       " 'like',\n",
       " 'mj',\n",
       " 'one',\n",
       " 'level',\n",
       " 'another',\n",
       " 'think',\n",
       " 'people',\n",
       " 'stay',\n",
       " 'away',\n",
       " 'try',\n",
       " 'give',\n",
       " 'wholesome',\n",
       " 'message',\n",
       " 'ironically',\n",
       " 'mj',\n",
       " 'bestest',\n",
       " 'buddy',\n",
       " 'movie',\n",
       " 'girl',\n",
       " 'michael',\n",
       " 'jackson',\n",
       " 'truly',\n",
       " 'one',\n",
       " 'talented',\n",
       " 'people',\n",
       " 'ever',\n",
       " 'grace',\n",
       " 'planet',\n",
       " 'guilty',\n",
       " 'well',\n",
       " 'attention',\n",
       " 'gave',\n",
       " 'subject',\n",
       " 'hmmm',\n",
       " 'well',\n",
       " 'know',\n",
       " 'people',\n",
       " 'different',\n",
       " 'behind',\n",
       " 'closed',\n",
       " 'doors',\n",
       " 'know',\n",
       " 'fact',\n",
       " 'either',\n",
       " 'extremely',\n",
       " 'nice',\n",
       " 'stupid',\n",
       " 'guy',\n",
       " 'one',\n",
       " 'sickest',\n",
       " 'liars',\n",
       " 'hope',\n",
       " 'latter']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터\n",
    "num_features = 300 # 워드 벡터 특징값 수  (임베딩 벡터 차원) \n",
    "min_word_count = 40 # 단어에 대한 최소 빈도 수 \n",
    "num_workers = 4 # 학습을 위한 프로세스 개수      \n",
    "context = 10 # 컨텍스트 윈도우 크기          \n",
    "downsampling = 1e-3 # 빠른 학습을 위해 정답 단어 레이블에 대한 다운샘플링 비율(0.001이 좋음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 학습 진행사항 확인\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "   level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-08 12:52:44,285 : INFO : collecting all words and their counts\n",
      "2021-01-08 12:52:44,286 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-01-08 12:52:44,547 : INFO : PROGRESS: at sentence #10000, processed 1205900 words, keeping 51374 word types\n",
      "2021-01-08 12:52:44,828 : INFO : PROGRESS: at sentence #20000, processed 2397955 words, keeping 67660 word types\n",
      "2021-01-08 12:52:44,974 : INFO : collected 74064 word types from a corpus of 2989726 raw words and 25000 sentences\n",
      "2021-01-08 12:52:44,975 : INFO : Loading a fresh vocabulary\n",
      "2021-01-08 12:52:45,022 : INFO : effective_min_count=40 retains 8161 unique words (11% of original 74064, drops 65903)\n",
      "2021-01-08 12:52:45,023 : INFO : effective_min_count=40 leaves 2628958 word corpus (87% of original 2989726, drops 360768)\n",
      "2021-01-08 12:52:45,050 : INFO : deleting the raw counts dictionary of 74064 items\n",
      "2021-01-08 12:52:45,053 : INFO : sample=0.001 downsamples 30 most-common words\n",
      "2021-01-08 12:52:45,054 : INFO : downsampling leaves estimated 2496173 word corpus (94.9% of prior 2628958)\n",
      "2021-01-08 12:52:45,076 : INFO : estimated required memory for 8161 words and 300 dimensions: 23666900 bytes\n",
      "2021-01-08 12:52:45,077 : INFO : resetting layer weights\n",
      "2021-01-08 12:52:46,871 : INFO : training model with 4 workers on 8161 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2021-01-08 12:52:47,881 : INFO : EPOCH 1 - PROGRESS: at 42.05% examples, 1049741 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:48,884 : INFO : EPOCH 1 - PROGRESS: at 84.78% examples, 1057419 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:49,214 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-01-08 12:52:49,218 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-08 12:52:49,225 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-08 12:52:49,233 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-08 12:52:49,234 : INFO : EPOCH - 1 : training on 2989726 raw words (2496464 effective words) took 2.4s, 1057944 effective words/s\n",
      "2021-01-08 12:52:50,238 : INFO : EPOCH 2 - PROGRESS: at 39.78% examples, 998388 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:51,242 : INFO : EPOCH 2 - PROGRESS: at 84.78% examples, 1059826 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:51,538 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-01-08 12:52:51,542 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-08 12:52:51,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-08 12:52:51,560 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-08 12:52:51,561 : INFO : EPOCH - 2 : training on 2989726 raw words (2496044 effective words) took 2.3s, 1074067 effective words/s\n",
      "2021-01-08 12:52:52,567 : INFO : EPOCH 3 - PROGRESS: at 44.36% examples, 1113866 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:53,571 : INFO : EPOCH 3 - PROGRESS: at 88.74% examples, 1109399 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:53,788 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-01-08 12:52:53,797 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-08 12:52:53,807 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-08 12:52:53,808 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-08 12:52:53,808 : INFO : EPOCH - 3 : training on 2989726 raw words (2496133 effective words) took 2.2s, 1113143 effective words/s\n",
      "2021-01-08 12:52:54,818 : INFO : EPOCH 4 - PROGRESS: at 42.41% examples, 1058572 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:55,820 : INFO : EPOCH 4 - PROGRESS: at 86.42% examples, 1078767 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:56,090 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-01-08 12:52:56,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-08 12:52:56,113 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-08 12:52:56,114 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-08 12:52:56,114 : INFO : EPOCH - 4 : training on 2989726 raw words (2495943 effective words) took 2.3s, 1083919 effective words/s\n",
      "2021-01-08 12:52:57,121 : INFO : EPOCH 5 - PROGRESS: at 43.02% examples, 1079713 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:58,130 : INFO : EPOCH 5 - PROGRESS: at 89.12% examples, 1110343 words/s, in_qsize 7, out_qsize 0\n",
      "2021-01-08 12:52:58,345 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-01-08 12:52:58,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-01-08 12:52:58,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-01-08 12:52:58,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-01-08 12:52:58,363 : INFO : EPOCH - 5 : training on 2989726 raw words (2496276 effective words) took 2.2s, 1112484 effective words/s\n",
      "2021-01-08 12:52:58,363 : INFO : training on a 14948630 raw words (12480860 effective words) took 11.5s, 1086052 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec(sentences, \n",
    "                          workers=num_workers,\n",
    "                         size=num_features,\n",
    "                         min_count=min_word_count,\n",
    "                         window=context,\n",
    "                         sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-08 12:56:31,259 : INFO : saving Word2Vec object under ../snapshot/300features_40minwords_10context, separately None\n",
      "2021-01-08 12:56:31,261 : INFO : not storing attribute vectors_norm\n",
      "2021-01-08 12:56:31,262 : INFO : not storing attribute cum_table\n",
      "2021-01-08 12:56:31,496 : INFO : saved ../snapshot/300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "# 모델의 하이퍼 파라미터를 설정한 내용을 모델 이름에 담는다면 나중에 참고하기 좋을 것\n",
    "# 모델을 저장하면 Word2Vec.load()를 통해 다시 사용할 수 있음\n",
    "model_name = '../snapshot/300features_40minwords_10context'\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(words, model, num_features):\n",
    "    # 출력 벡터 초기화\n",
    "    feature_vector = np.zeros((num_features), dtype=np.float32)\n",
    "    \n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index2word) # 단어 사전\n",
    "    \n",
    "    for w in words:\n",
    "        if w in index2word_set:\n",
    "            num_words+=1\n",
    "            # 사전에 해당하는 단어에 대해 단어 벡터를 더함 \n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "    \n",
    "    # 문장의 단어 수만큼 나누어 단어 벡터의 평균을 취함\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews, model, num_features):\n",
    "    dataset = list()\n",
    "    for s in reviews:\n",
    "        dataset.append(get_features(s, model, num_features))\n",
    "    \n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohyeji/anaconda3/envs/tf2/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "test_data_vecs = get_dataset(sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohyeji/anaconda3/envs/tf2/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02640619, -0.14458393, -0.09509004, -0.08096875,  0.04741286,\n",
       "       -0.03741783,  0.0219393 ,  0.03156377,  0.08235965, -0.06761346,\n",
       "       -0.03597539, -0.01125347, -0.15502955, -0.06209488, -0.18695156,\n",
       "        0.03714039,  0.08632327, -0.01063505,  0.03024327, -0.05743328,\n",
       "        0.1429146 , -0.15087967,  0.05187488,  0.0617708 ,  0.159874  ,\n",
       "       -0.10153214, -0.01214275,  0.08777526, -0.15193017, -0.01255662,\n",
       "        0.0801809 , -0.10454084,  0.0387894 , -0.17809501, -0.17801481,\n",
       "       -0.14112939,  0.01613287,  0.02805205,  0.0159293 ,  0.03151309,\n",
       "        0.01988512, -0.02880661,  0.10957897,  0.09595552,  0.26332775,\n",
       "        0.13695167,  0.00702472, -0.00435817,  0.05849722,  0.02389651,\n",
       "        0.05995859,  0.054804  ,  0.0435122 ,  0.00068778, -0.11518065,\n",
       "        0.0794315 ,  0.05362769, -0.24948503, -0.04995171, -0.1138126 ,\n",
       "       -0.03293214,  0.1949825 ,  0.10471201,  0.01226235, -0.24788082,\n",
       "        0.13863872, -0.20625623, -0.05579423,  0.23053773, -0.10491943,\n",
       "       -0.02750718, -0.01788006, -0.09331053, -0.01615483, -0.14648262,\n",
       "       -0.11701515, -0.04484864, -0.08393542,  0.15779896, -0.10979   ,\n",
       "        0.09188528,  0.04883891, -0.03009709, -0.013858  ,  0.15208834,\n",
       "        0.04773508,  0.04199508, -0.17709227, -0.04597493,  0.12869443,\n",
       "       -0.05497533,  0.29284006, -0.00230303,  0.00293589, -0.09905905,\n",
       "       -0.07505506, -0.04214466,  0.11030491, -0.1476997 ,  0.22979267,\n",
       "        0.04409955,  0.1471403 ,  0.11066963, -0.02395348, -0.07979241,\n",
       "        0.11628809, -0.06610072, -0.06863285,  0.00894669,  0.04348393,\n",
       "        0.01026219,  0.20944504, -0.03283129, -0.13896245,  0.02015635,\n",
       "        0.00051198, -0.14043473, -0.00363406, -0.01558846,  0.00331306,\n",
       "        0.01731583,  0.04220476,  0.15308791, -0.01495828,  0.06456345,\n",
       "       -0.16875228,  0.05487783, -0.00911005,  0.04130454,  0.02799365,\n",
       "        0.02364538, -0.01770043,  0.18024005, -0.02187359,  0.04267668,\n",
       "       -0.02164834,  0.00187188, -0.12935346, -0.09569204, -0.03889897,\n",
       "       -0.01232803,  0.09539946,  0.07245555, -0.07350937, -0.27459082,\n",
       "        0.13407743, -0.088338  , -0.07637897, -0.00308089,  0.14546175,\n",
       "       -0.16859281,  0.07746997,  0.0363508 , -0.07236443, -0.18927826,\n",
       "       -0.16197982,  0.06142418,  0.00247475,  0.14077011,  0.01186919,\n",
       "        0.00330896,  0.10383486,  0.05738052, -0.03727549,  0.15763716,\n",
       "        0.06622747,  0.04906969,  0.04971212,  0.04525016, -0.06719822,\n",
       "       -0.00654787, -0.00494575, -0.03487174, -0.07141364, -0.19708884,\n",
       "        0.15038523,  0.01129875,  0.03363696, -0.05016124, -0.04852488,\n",
       "       -0.03676831,  0.02193644, -0.15059546,  0.02326725, -0.02418051,\n",
       "       -0.07458647, -0.03197586, -0.03145595, -0.11388733,  0.07605296,\n",
       "        0.00239746,  0.04269272,  0.1364615 ,  0.01966729,  0.05337025,\n",
       "        0.01185233,  0.27313182,  0.14648096, -0.12950583, -0.00816375,\n",
       "       -0.01993645, -0.08798748,  0.00073865,  0.00063861, -0.08234493,\n",
       "        0.05178176, -0.01236768, -0.03760098, -0.01508898,  0.11197543,\n",
       "        0.00475173, -0.01449067, -0.0207457 , -0.11878678,  0.06063968,\n",
       "       -0.22965083,  0.02309402,  0.078191  ,  0.08543475,  0.06854754,\n",
       "       -0.0329477 ,  0.01961785, -0.00844391,  0.11016196, -0.16732474,\n",
       "       -0.05176388, -0.05350276, -0.05654362,  0.0239173 , -0.03450182,\n",
       "        0.16510946, -0.05339186,  0.04082706,  0.07982357, -0.18530667,\n",
       "        0.10472317, -0.06341512,  0.0754159 ,  0.13933024, -0.05905608,\n",
       "       -0.05801731, -0.05464596,  0.04961345, -0.02742414,  0.01023476,\n",
       "        0.04796629,  0.08573821, -0.07042763, -0.0644158 ,  0.11470688,\n",
       "        0.14429861,  0.12290391, -0.07824925, -0.08171105,  0.07511945,\n",
       "       -0.03017207, -0.06902147, -0.18091771, -0.13017993,  0.00931943,\n",
       "       -0.02428465,  0.00722431,  0.04550672, -0.10663578, -0.08262797,\n",
       "        0.01389182, -0.04515894, -0.01959134, -0.16443644, -0.01042525,\n",
       "       -0.00665792,  0.1202042 ,  0.0533031 ,  0.1315065 ,  0.08911744,\n",
       "        0.01962859, -0.06467822,  0.08143385,  0.19603634, -0.1314575 ,\n",
       "       -0.10731872, -0.00422534, -0.11088341,  0.06562886, -0.01186152,\n",
       "       -0.07256512, -0.06319086, -0.07952316,  0.08067563, -0.02150384,\n",
       "       -0.13459092,  0.03882179,  0.00867674,  0.00629102,  0.0090435 ,\n",
       "       -0.07236823, -0.08406532,  0.01773479,  0.01311519,  0.05152513],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['sentences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.07590105,  0.12482008, -0.14356229, ..., -0.0393403 ,\n",
       "         0.29451394, -0.05616223],\n",
       "       [-0.2558206 ,  0.05033305,  0.3669831 , ..., -0.16925296,\n",
       "         0.38734385, -0.14674819],\n",
       "       [-0.42619082,  0.2628543 ,  0.4130558 , ..., -0.15671903,\n",
       "         0.2993253 , -0.06611255],\n",
       "       ...,\n",
       "       [-0.1997599 ,  0.12621206,  0.251406  , ..., -0.01236875,\n",
       "         0.04296463, -0.15083946],\n",
       "       [ 0.04327991,  0.17174765, -0.4576193 , ..., -0.04074266,\n",
       "         0.09678981, -0.09552169],\n",
       "       [-0.19706714, -0.08549628,  0.16449447, ..., -0.11568981,\n",
       "         0.11454067, -0.03168364]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_vecs # 실제 학습에 사용될 입력값 (임베딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 학습과 검증 데이터셋 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = test_data_vecs\n",
    "y = np.array(sentiments)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohyeji/anaconda3/envs/tf2/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862000\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %f\" % lgs.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_CLEAN_DATA = 'test_clean.csv'\n",
    "\n",
    "test_data = pd.read_csv(DATA_IN_PATH + TEST_CLEAN_DATA)\n",
    "\n",
    "test_review = list(test_data['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>naturally film main themes mortality nostalgia...</td>\n",
       "      <td>\"12311_10\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movie disaster within disaster film full great...</td>\n",
       "      <td>\"8348_2\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>movie kids saw tonight child loved one point k...</td>\n",
       "      <td>\"5828_4\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afraid dark left impression several different ...</td>\n",
       "      <td>\"7186_2\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accurate depiction small time mob life filmed ...</td>\n",
       "      <td>\"12128_7\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review          id\n",
       "0  naturally film main themes mortality nostalgia...  \"12311_10\"\n",
       "1  movie disaster within disaster film full great...    \"8348_2\"\n",
       "2  movie kids saw tonight child loved one point k...    \"5828_4\"\n",
       "3  afraid dark left impression several different ...    \"7186_2\"\n",
       "4  accurate depiction small time mob life filmed ...   \"12128_7\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_sentences = list()\n",
    "for review in test_review:\n",
    "    test_sentences.append(review.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohyeji/anaconda3/envs/tf2/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "test_data_vecs = get_dataset(test_sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_OUT_PATH = './data_out/'\n",
    "\n",
    "test_predicted = lgs.predict(test_data_vecs)\n",
    "\n",
    "if not os.path.exists(DATA_OUT_PATH):\n",
    "    os.makedirs(DATA_OUT_PATH)\n",
    "    \n",
    "ids = list(test_data['id'])\n",
    "answer_dataset = pd.DataFrame({'id': ids, 'sentiment': test_predicted})\n",
    "answer_dataset.to_csv(DATA_OUT_PATH + 'lgs_w2v_answer.csv', index=False, quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
